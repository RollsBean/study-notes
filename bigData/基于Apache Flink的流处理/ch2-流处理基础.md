# 第二章 流处理基础

本章介绍流处理的举出概念及其处理框架的需求。

## Dataflow 编程概述

### Dataflow 图

**Dataflow** 程序描述了数据如何在不同操作之间的流动。Dataflow 程序通常表示为有向图。图中的定点称为**算子**，表示计算；而**边**便是数据依赖关系。
算子是 Dataflow 程序的基本功能单元，它们从输入获取数据。没有输入端的算子称为数据源，没有输出端的算子称为数据汇。一个 Dataflow 图至少有一个数据源
和一个数据汇。下图2-1 展示了一个从推文输入流中提取并统计主题标签的 Dataflow 程序。

![Flink Dataflow 2-1](../../image/bigData/基于Apache%20Flink的流处理/Flink%20Dataflow%202-1.png)

图2-1的Dataflow 图被称为逻辑图。为了执行 Dataflow 程序，需要转化为物理 Dataflow 图，这个图会指定程序的执行细节。当我们使用分布式引擎时，每个
算子会再不同物理机上运行多个并行任务。下图2-2中（物理 Dataflow 图），顶点代表任务。

![Flink Dataflow 2-2](../../image/bigData/基于Apache%20Flink的流处理/Flink%20Dataflow%202-2.png)

### 数据并行和任务并行

Dataflow 图的并行性可以通过多种方式加以利用。首先，输入数据分组，让同一操作的多个任务并行执行在不同数据子集上，这种称为数据并行（data parallelism）。
数据并行很有用，它可以将计算负载分配到多个节点。再者，你可以让不同算子的任务并行计算，这种并行称为任务并行（task parallelism）。通过任务并行，可以
更好利用集群的计算资源。

### 数据交换策略

数据交换策略定义了如何将数据项分配给物理 Dataflow 图中的不同任务。这可以有引擎自动选择，也可以显式指定。

* **转发策略**（forward strategy）在发送端任务和接收端任务一对一进行数据传输。如果两端在同一物理机器上，该交换策略可以避免网络通信。
* **广播策略**（broadcast strategy）会把每个数据项发往下游算子的全部并行任务。该策略会把数据复制多份且涉及网络通信，因此代价十分昂贵。
* **基于键值策略**（key-based strategy）根据某一键值属性对数据分区，并保证键值相同的数据项会交由同一任务处理。
* **随机策略**（random strategy）会将数据均匀分配到算子的所有任务，以实现计算任务的负载均衡。 

![Flink data exchange strategies 2-3](../../image/bigData/基于Apache%20Flink的流处理/Flink%20data%20exchange%20strategies%202-3.png)

## 并行流处理

**数据流**：数据流是一个可能无限的时间序列。

### 延迟和吞吐

因为流式应用会持续执行并且输入可能是无限的，所以再数据流处理中没有总执行时间的概念。我们用延迟和吞吐来表示这两方面的性能需求。

#### 延迟

延迟表示处理一个事件所需的时间。本质上它是从接收事件到在输出中关村到事件处理效果的时间间隔。

在流处理中，延迟是以时间片（例如毫秒）为单位测量的。根据应用不同，你可能会关注平均延迟、最大延迟或延迟的百分位数值。

#### 吞吐

吞吐是用来衡量系统处理能力（处理速率）的指标，它告诉我们系统每单位时间可以处理多少实际。吞吐的衡量方式是计算每个单位时间的事件或操作数。处理速率取决于
数据到来速率，因此吞吐量低不一定意味着性能差。换言之，首先要关注峰值吞吐，即性能上限。如果系统持续以力不能及的高速率接收数据，那么缓冲区可能会用尽，
继而导致数据丢失。这种情况称为**背压**（backpressure）。

#### 延迟与吞吐

通过并行处理多条数据流，可以再处理更多事件的同时降低延迟。

### 数据流上的操作

流处理引擎通常会提供一系列内置操作来实现数据流的获取、转换和输出。这些操作既可以是无状态的（stateless），也可以是有状态的（stateful）。

#### 数据接入和数据输出

数据接入和数据输出操作允许流处理引擎和外部系统进行通信。数据接入操作逻辑的算子称为数据源。

#### 转换操作

转换操作是一类"只过一次"的操作，如下图所示，转换逻辑可以是算子内置的，也可以由用户自定义函数提供。

![Transfomation operate 2-4](../../image/bigData/基于Apache%20Flink的流处理/Transfomation%20operate%202-4.png)
**图2-4：带有函数的流式算子会将每个到来事件的颜色变深**

#### 滚动聚合

滚动聚合（如求和、求最小值和求最大值）会根据每个到来的事件持续更新结果。聚合操作都是有状态的，新到来的事件合并到已有状态的聚合值。图2-5展示了求最小
值的滚动聚合，其算子会维护当前的最小值。

![minimum aggregation operation 2-5](../../image/bigData/基于Apache%20Flink的流处理/minimum%20aggregation%20operation%202-5.png)
**图2-5：求最小值的滚动聚合操作**

#### 窗口操作

转换操作和滚动聚合每次处理一个时间来产生输出并可能更新状态。然而有些操作必须收集并缓冲记录才能计算结果，比如流式join或求中位数的整体聚合。为了在无限
流上高效执行这些操作，必须对数据量加以限制。

使用场景：实时路况信息，只需知道最近几分钟的信息。

窗口操作会持续创建一些称为"桶"的有限事件集合，并允许对这个集合进行计算。窗口的行为由一系列策略定义的，策略的指定可以基于时间（最近5秒钟），数量
（最新的100个事件）或其他数据属性。常见窗口类型如下：

* **滚动窗口**（tumbling window）将事件分配到长度固定且相互不重叠的桶中。在窗口边界通过后，所有事件会发送给计算函数进行处理。

![tumbling window 2-6](../../image/bigData/基于Apache%20Flink的流处理/tumbling%20window%202-6.png)
**图2-6：基于数量的滚动窗口**

![time-based tumbling window 2-7](../../image/bigData/基于Apache%20Flink的流处理/tumbling%20window%20time-based%202-7.png)
**图2-6：基于时间的滚动窗口**

* **滑动窗口**（sliding window）将事件分配到大小固定且允许相互重叠的桶中，这意味着每个事件可能会同时属于多个桶。我们通过指定**长度**和**划定间隔**
来定义滑动窗口。

![sliding window 2-8](../../image/bigData/基于Apache%20Flink的流处理/sliding%20window%202-8.png)
**图2-8：长度为4个事件滑动间隔为3个事件的基于数量的滑动窗口**

* **会话窗口**（session window）在一些场景的真实场景中非常有用。比如在线分析用户行为，在该应用中我们要把事件按照同一活动或会话来源进行分组。例如
用户浏览一连串的新闻文章是一个会话，可以理解成页面请求的一个session。会话窗口根据会话间隔（session gap）将事件分为不同的会话，该间隔值就是会话
关闭前非活动时间长度。

![session window 2-8](../../image/bigData/基于Apache%20Flink的流处理/session%20window%202-9.png)
**图2-9：会话窗口**

## 时间语义

本节讨论引擎如何基于乱序事件产生精确结果，以及如何使用数据流景行历史事件处理并实现"时间旅行"。

### 流处理场景下一分钟的含义

如果要持续计算结果，比如每分钟计算一次，一分钟的含义可以是处理时间（processing time）也可以是事件时间（event time）。

### 处理时间（processing time）

处理时间是当前流处理算子所在机器上的本地时钟时间。这个时间段是按照机器时间测量的。如果因为数据延迟导致进入流的数据晚了，这样可能会导致数据处于不同的
时间窗口中。

### 事件时间（event time）

事件时间是数据流中事件实际发生的时间，它以附加在数据流中事件的时间戳为依据。这些时间戳在进入流处理管道之前就存在，它们是数据本身的一个字段。这种情况下，
就算数据由延迟，但是它也可以在同一个窗口进行计算。

使用事件时间需要克服如何处理延迟事件。普遍存在的无序问题也可以解决。

### 水位线

如上，需要考虑如何决定事件时间窗口的触发时机？因为事件时间是数据本身的一个时间字段，它可能是乱序的，需要去考虑怎么触发时间窗口结束条件。

**水位线**是一个全局进度指标，表示我们确信不会再有延迟时间到来的某个时间点。意思就是比如我们确定了10:00是结束条件，那么遇到这个条件（水位线）就结束，
不再考虑后面是否还有小于10：00的事件。本质上，水位线提供了一个逻辑时钟，用来通知系统当前的事件时间。当一个算子接收到时间为T的水位线，就可以认为不再
收到任何时间戳小于或等于 T 的事件了。

水位线的作用其实就相当于超时时间，它允许我们在准确性和延迟之间做出取舍。水位线保守，也就是超时时间长，可信度会得到保证，但是处理延迟会增加；水位线
激进，比如设置的很小，超时时间就很短，它降低了延迟但是也带来了低可信度，因为会有更多的数据丢失。

实际应用中，水位线很难完美确定。

### 处理时间与事件时间

处理时间使用场景：实时监控仪表盘，它会接收并展示时间聚合结果。

## 状态和一致性模型

**状态**在数据处理中无处不在。聚合函数需要累积状态。有些算子也需要使用传入的事件和内部状态来计算输出。

支持有状态算子的挑战：

状态管理  
&nbsp; &nbsp; &nbsp; &nbsp;系统需要高效地管理状态并保证高并发的并发更新安全。

状态划分  
&nbsp; &nbsp; &nbsp; &nbsp;由于有些结果依赖于状态和到来的事件，导致状态并行化变得很复杂。幸运的是，我们可以按照键值划分并独立管理。
    
状态恢复  
&nbsp; &nbsp; &nbsp; &nbsp;最大的挑战是有状态算子需要保证状态可以恢复。

### 任务故障

流式作业的算子状态很重要，流式作业一般运行时间都很长，如果发生故障后无法立即恢复算子状态，而通过重新处理来恢复状态代价会很高并且耗时。

#### 什么是任务故障？

任务执行步骤：

1. 接收事件并将它们存在本地缓冲区；
2. 选择性地更新内部状态；
3. 产生输出记录。

上述任何一个步骤都可能发生故障。

### 结果故障

保证应用状态的一直性和保证输出的一致性不是一回事。一旦数据写出，除非目标系统支持事务，否则结果的准确性很难保证。

#### 至多一次

发生故障最简单的措施就是既不恢复丢失的状态，也不重放丢失的事件。至多一次是最简单的情况，它保证每个事件至多被处理一次。也就是宁可丢数据也不重复消费，
如果你能接受这个近似结果，那这种保障也可以接受。


#### 至少一次

对于大多数应用而言，用户期望不丢失事件，这类保障被称为至少一次。如果正确性仅依赖于信息的完整度，那它也能被接受。也就是如果保证幂等性，那可以被接受。

为了确保至少一次结果语义的正确性，需要想办法从源头或缓冲区重放事件。持久化事件日志会将所有事件写入永久存储，这样发生故障时就可以重放事件。另一个实现
方发是采用记录确认（record acknowledgements）。该方法将所有事件存在缓冲区中，直到处理管道中所有任务都确认某个事件已经处理完毕再丢弃。

#### 精确一次

精确一次最严格，也最难实现，它表示事件既没有丢失也没有重复消费。

精确一次保障是以至少一次保障为前提，因此同样需要数据重放机制。另外，流处理引擎要确保内部状态的一致性，即故障恢复后，引擎需要知道某个事件是否已经被计算
并更新到状态上。事务性更新是实现该目标的一个方法，但会带来极大的性能开销。Flink采用轻量级检查点机制来实现精确一次保障。

#### 端到端的精确一次

端到端的保障是值在整个数据处理管道上的结果都是正确的。


## 小结

主要学习了数据量处理相关的基础知识。如 Dataflow 图、延迟和吞吐、基本流式操作、窗口操作和时间语义等。
